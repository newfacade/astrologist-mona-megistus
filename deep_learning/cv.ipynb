{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.image agumentation\n",
    "\n",
    "1. flipping\n",
    "2. croping\n",
    "3. change color\n",
    "4. rotating\n",
    "5. overlying all the above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.fine-tuning\n",
    "\n",
    "to migrate the knowledge learned from the source datasets to the target datasets, we introduce fine-tuning:\n",
    "\n",
    "1.pre-train a nerual network model, i.e source model, on the source dataset.\n",
    "\n",
    "2.create a nerual network, i.e target model, that replicates source model designs and weights except the output layer.\n",
    "\n",
    "3.fix output size, randomly initialize target output layer.\n",
    "\n",
    "4.train target model on the target dataset.\n",
    "\n",
    "![jupyter](finetune.svg)\n",
    "\n",
    "for example, source model trained on image-net\n",
    "\n",
    "while our target is only to identify hot-dogs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.object detection\n",
    "\n",
    "from image classification to object detection\n",
    "\n",
    "1.one target $\\rightarrow$ multiple targets\n",
    "\n",
    "2.also need to obtain specific positions in the image\n",
    "\n",
    "we usually use bounding box to describe the target location.\n",
    "\n",
    "![jupyter](bounding-box1.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
