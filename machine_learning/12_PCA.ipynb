{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maximum variance formulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "consider a dataset $\\{x_{i}\\}$ where $i=1,...,n$ and $x_{i} \\in \\mathbb{R}^{d}$.\n",
    "\n",
    "our goal is to project the data onto a space having dimensionality $k < d$ while maximizing the variance of the projected data. \n",
    "\n",
    "to begin with, consider the projection onto a one-dimensional space$(k=1)$.\n",
    "\n",
    "we can define the direction of this space by a vector $u_{1} \\in \\mathbb{R}^{d}$, we can choose $u_{1}$ to be a unit vector so that $u_{1}^{T}u_{1} = 1$.\n",
    "\n",
    "each data point $x_{i}$ is then projected onto a scalar value $u_{1}^{T}x_{i}$, then mean of the projected data:\n",
    "\n",
    "$$\\frac{1}{n}\\sum_{i=1}^{n}u_{1}^{T}x_{i} = u_{1}^{T}\\overline{x}$$\n",
    "\n",
    "the variance of the projected data:\n",
    "\n",
    "$$\\frac{1}{n}\\sum_{i=1}^{n}(u_{1}^{T}x_{i} - u_{1}^{T}\\overline{x})^{2} = \\frac{1}{n}\\sum_{i=1}^{n}u_{1}^{T}(x_{i} - \\overline{x})(x_{i} - \\overline{x})^{T}u_{1} = u_{1}^{T}Su_{1}$$\n",
    "\n",
    "where\n",
    "\n",
    "$$S = \\frac{1}{n}\\sum_{i=1}^{n}(x_{i} - \\overline{x})(x_{i} - \\overline{x})^{T}$$\n",
    "\n",
    "now we can formalize our problem as:\n",
    "\n",
    "$$\\underset{u_{1}}{min}\\ -u_{1}^{T}Su_{1}$$\n",
    "$$s.t\\quad u_{1}^{T}u_{1} = 1$$\n",
    "\n",
    "the lagrangian of this optimization problem:\n",
    "\n",
    "$$L(u_{1}, \\lambda_{1}) = -u_{1}^{T}Su_{1} + \\lambda_{1}(u_{1}^{T}u_{1} - 1)$$\n",
    "\n",
    "the primal:\n",
    "\n",
    "$$\\underset{u_{1}}{min}\\ \\underset{\\lambda_{1}}{max}\\ L(u_{1}, \\lambda_{1})$$\n",
    "\n",
    "primal satisfy the KKT conditions, so equivalent to dual:\n",
    "\n",
    "$$\\underset{\\lambda_{1}}{max}\\ \\underset{u_{1}}{min}\\ L(u_{1}, \\lambda_{1})$$\n",
    "\n",
    "setting the derivative with respect to $u_{1}$ equal to zero, we have:\n",
    "\n",
    "$$Su_{1} = \\lambda_{1}{u_{1}}$$\n",
    "\n",
    "which say that $u_{1}$ must be a eigenvector of $S$, if we left-multiply by $u_{1}^{T}$ and make use of $u_{1}^{T}u_{1} = 1$, we get:\n",
    "\n",
    "$$u_{1}^{T}Su_{1} = \\lambda_{1}$$\n",
    "\n",
    "and so the variance will be a maximum when we set $u_{1}$ equal to the eigenvector having the largest eigenvalue $\\lambda_{1}$. this eigenvector is known as the first principal component.\n",
    "\n",
    "we can define the additional principal components in an increamental fashion by choosing each new direction to be that which maximizes the projected variance amongst all possible directions orthogonal to those already considered.\n",
    "\n",
    "second principal component:\n",
    "\n",
    "$$\\underset{u_{2}}{min}\\ -u_{2}^{T}Su_{2}$$\n",
    "$$s.t\\quad u_{2}^{T}u_{2} = 1, u_{1}^{T}u_{2} = 0$$\n",
    "\n",
    "like before, using lagrangian we derive:\n",
    "\n",
    "$$Su_{2} = \\lambda_{2}{u_{2}} + \\phi{u_{1}}$$\n",
    "\n",
    "left multiply by $u_{1}^{T}$:\n",
    "\n",
    "$$u_{1}^{T}Su_{2} = \\lambda_{2}u_{1}^{T}{u_{2}} + \\phi{u_{1}^{T}}{u_{1}}$$\n",
    "\n",
    "analyzing each component:\n",
    "\n",
    "$$u_{1}^{T}Su_{2} = u_{2}^{T}Su_{1} = u_{2}^{T}\\lambda_{1}u_{1} = \\lambda{u_{1}^{T}u_{2}} = 0$$\n",
    "$$u_{1}^{T}{u_{2}} = 0$$\n",
    "$${u_{1}^{T}}{u_{1}} = 1$$\n",
    "\n",
    "we get:\n",
    "\n",
    "$$\\phi = 0$$\n",
    "\n",
    "back to zero derivative we have:\n",
    "\n",
    "$$Su_{2} = \\lambda_{2}{u_{2}}$$\n",
    "$$u_{2}^{T}Su_{2} = \\lambda_{2}$$\n",
    "\n",
    "so $\\lambda_{2}$ is the second largest eigenvector of $S$.\n",
    "\n",
    "by induction, we can show that $i$-th principal component is the $i$-th largest eigenvector of $S$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# properties of non-negative definite symmetric real matrix\n",
    "\n",
    "$$S = \\frac{1}{n}\\sum_{i=1}^{n}(x_{i} - \\overline{x})(x_{i} - \\overline{x})^{T}$$ \n",
    "\n",
    "is of that kind."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minimum-error formulation\n",
    "\n",
    "a complete orthonormal basis vectors $u_{i}$ in $\\mathbb{R}^{d}$:\n",
    "\n",
    "$$u_{i}^{T}u_{j} = \\delta_{ij}$$\n",
    "\n",
    "$x_{k}$ coordinate with respect to $u_{i}$ is $x_{k}^{T}u_{i}$, so:\n",
    "\n",
    "$$x_{k} = \\sum_{i=1}^{d}(x_{k}^{T}u_{i})u_{i}$$\n",
    "\n",
    "$x_{k}$ can be approximated by the $m$-dimensional subspace representation plus a constant:\n",
    "\n",
    "$$\\tilde{x}_{k} = \\sum_{i=1}^{m}z_{ki}u_{i} + \\sum_{i=m+1}^{d}b_{i}u_{i}$$\n",
    "\n",
    "where $z_{ki}$ depend on the particular data point, whereas ${b_{i}}$ are constants that are the same for all data points.\n",
    "\n",
    "our goal is to minimize:\n",
    "\n",
    "$$J = \\frac{1}{n}\\sum_{k=1}^{d}\\left \\| x_{k} - \\tilde{x}_{k} \\right \\|^{2} $$\n",
    "\n",
    "setting the derivative with respect to $z_{ni}$ to zero, and making use of the orthonormality conditions, we obtain:\n",
    "\n",
    "$$z_{ni} = x_{n}^{T}u_{i}$$\n",
    "\n",
    "similarly, we obtain:\n",
    "\n",
    "$$b_{i} = \\overline{x}^{T}u_{i}$$\n",
    "\n",
    "substitude for $z_{ni}$ and $b_{i}$, we obtain:\n",
    "\n",
    "$$x_{k} - \\tilde{x}_{k} = \\sum_{i=m+1}^{d}((x_{k} - \\overline{x}_{k})^{T}u_{i})u_{i}$$\n",
    "\n",
    "finally our goal is to minimize:\n",
    "\n",
    "$$J = \\frac{1}{n}\\sum_{k=1}^{n}\\sum_{i=m+1}^{d}(x_{k} - \\overline{x}_{k})^{2} = \\sum_{i=m+1}^{d}u_{i}^{T}Su_{i}$$\n",
    "\n",
    "this is similar to the maximum variance formulation in the opposite direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
